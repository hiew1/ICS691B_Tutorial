{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*What is Ray?*\n",
        "\n",
        "Ray is a unified framework for scaling Python and AI applications. It has a core framework, and a toolkit of libraries to manage AI workloads, and to run Python codes in a distributed manner to speed up code execution. \n"
      ],
      "metadata": {
        "id": "5FkcK_W7OuTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*What are the Ray's libraries?*\n",
        "\n",
        "Ray Core: Scale General Python Applications\n",
        "\n",
        "Ray AIR: Scale AI Applications\n",
        "\n",
        "Ray Datasets: Scale data ingest and preprocessing\n",
        "\n",
        "Ray Train: Scale machine learning training\n",
        "\n",
        "Ray Tune: Scale hyperparameter tuning\n",
        "\n",
        "Ray Serve: Scale model serving\n",
        "\n",
        "Ray RLlib: Scale reinforcement learning\n",
        "\n",
        "There are also other Ray libraries such as Ray Workflows, Distributed multiprocessing.Pool, and so on. "
      ],
      "metadata": {
        "id": "2o-h9SrNRV4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we could use ray in our Python code, we would need to install it like so:\n",
        "!pip install ray\n",
        "\n",
        "# After installation, we will import ray into our code like so:\n",
        "import ray"
      ],
      "metadata": {
        "id": "ckZ51jvgsBtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019388fb-0d06-43a6-a1b0-635d62728a27"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray) (3.8.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.51.1)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.8/dist-packages (from ray) (20.17.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray) (22.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray) (2.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray) (0.3.6)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (5.10.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.11.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Difference between a Ray remote function vs a Regular Python function*"
      ],
      "metadata": {
        "id": "3SE7f_yvR-mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A regular Python function looks like this\n",
        "def do_something(x):\n",
        "  return x\n",
        "\n",
        "# A Ray remote function looks like this\n",
        "@ray.remote\n",
        "def do_something(x):\n",
        "  return x"
      ],
      "metadata": {
        "id": "vDmjxMS7SOip"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To call the remote function, we will have to use .remote like this:\n",
        "do_something(\"x\").remote()"
      ],
      "metadata": {
        "id": "McbuWJQg4j6w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To turn a regular Python function into a Ray function, we simply put \"@ray.remote\" annotation above a regular Python function, as shown like the code above. "
      ],
      "metadata": {
        "id": "VjudmkRMm59e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Why do we turn a regular Python function into a Ray function?*\n",
        "\n",
        "We use Ray function because it can be executed in a Ray cluster asynchronously. This is to allow a function to be called in an asynchronous manner, from a remote Ray cluster, which can help setting up a distributed system in such a way that functions can be run in a distributed manner, speeding up the processing of big data. "
      ],
      "metadata": {
        "id": "dIbNj6xNplP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we annotate a function to turn it into a Ray function, we first need to initiate a Ray service using ray.init(). \n",
        "\n",
        "Otherwise, Ray remote functions won't work."
      ],
      "metadata": {
        "id": "wxGH0PDAoX41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopping a Ray instance / service in case one is already running\n",
        "ray.shutdown()\n",
        "\n",
        "\n",
        "# Starting a Ray instance / service on a single machine\n",
        "ray.init()"
      ],
      "metadata": {
        "id": "3U3LRO9RVjsk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3f01e8ed-589c-4fb0-b788-76cb3e27af21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-16 09:36:04,383\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.16', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '172.28.0.12', 'raylet_ip_address': '172.28.0.12', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-12-16_09-36-01_813818_9608/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-12-16_09-36-01_813818_9608/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-12-16_09-36-01_813818_9608', 'metrics_export_port': 39429, 'gcs_address': '172.28.0.12:56873', 'address': '172.28.0.12:56873', 'dashboard_agent_listen_port': 52365, 'node_id': '53063ecbd138c39fa1a62b0a37cf20f26dad5cc3aa0558f0c8e6d2c9'})"
            ],
            "text/html": [
              "<div>\n",
              "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
              "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
              "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
              "            <g id=\"layer-1\">\n",
              "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
              "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
              "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
              "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
              "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
              "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
              "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
              "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
              "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
              "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
              "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
              "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
              "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
              "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
              "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
              "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
              "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
              "            </g>\n",
              "        </svg>\n",
              "        <table>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
              "                <td style=\"text-align: left\"><b>3.8.16</b></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
              "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
              "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
              "</tr>\n",
              "\n",
              "        </table>\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ray.init() can only be called once and cannot be called twice. To shut it down, call ray.shutdown():"
      ],
      "metadata": {
        "id": "EOkRqDiZqvzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shutting down a Ray service. \n",
        "ray.shutdown()"
      ],
      "metadata": {
        "id": "6B1cUvHYrAdL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*A simple example of using Ray function in Python code*"
      ],
      "metadata": {
        "id": "qy3pZnwqrUFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ray into our Python code\n",
        "import ray\n",
        "import time\n",
        "\n",
        "# If there's a Ray instance already running, shut it down first\n",
        "ray.shutdown()\n",
        "\n",
        "# Initialize a Ray instance / service \n",
        "ray.init()\n",
        "\n",
        "# Annotate a function so it becomes a Ray remote function\n",
        "@ray.remote\n",
        "def sleep_function(i):\n",
        "  time.sleep(1)\n",
        "  return i\n",
        "\n",
        "# Recording the starting time\n",
        "start_time = time.time()\n",
        "\n",
        "time_index = [sleep_function.remote(i) for i in range(4)]\n",
        "\n",
        "# Print the time it takes for the Ray remote function to execute\n",
        "execution_time_ray = time.time() - start_time\n",
        "print(execution_time_ray)\n",
        "\n",
        "# Printing the output of ray.get, which returns an object or list of objects from the object ID or list of object IDs obtained from the .remote function\n",
        "# ray.get is a synchronous function (it will block other function from executing until the corresponding object is available or all the objects in the list are available)\n",
        "print(ray.get(time_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-wAUlFzsaPf",
        "outputId": "cbf4da3f-75cc-4ac4-a138-4287b576e584"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-16 09:36:12,255\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.19228267669677734\n",
            "[0, 1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In comparison, the same Python program without using Ray would look like this:"
      ],
      "metadata": {
        "id": "qT0XWdtXvaNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def sleep_function(i):\n",
        "  time.sleep(1)\n",
        "  return i\n",
        "\n",
        "# Recording the starting time\n",
        "start_time = time.time()\n",
        "\n",
        "time_index = [sleep_function(i) for i in range(4)]\n",
        "\n",
        "# Print the time it takes for the Ray remote function to execute\n",
        "execution_time_regular = time.time() - start_time\n",
        "print(execution_time_regular)\n",
        "\n",
        "print(time_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnIMWjOqvfpW",
        "outputId": "918d69ab-fef7-4779-9f49-c559a3df1983"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.004140138626099\n",
            "[0, 1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference in execution time is significant. \n",
        "\n",
        "In my test run, the execution time of the regular Python code without Ray is 4.008\n",
        "\n",
        "Whereas the execution time with Ray is 0.015\n",
        "\n",
        "This is because the regular Python code's execution is running the for loop sequentially, therefore the time of execution stacks up with each function call in the for loop. \n",
        "\n",
        "Whereas the Ray's code execution, each remote function in the for loop is able to start running remotely in a Ray local instance asynchronously without needing to wait for the previous function call to finish. "
      ],
      "metadata": {
        "id": "0nfm8LTIwJfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Execution time visualization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "with_or_without_ray = ['Regular', 'Ray']\n",
        "execution_time = [execution_time_regular, execution_time_ray]\n",
        "ax.bar(with_or_without_ray,execution_time)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "TQZyeLc91bV8",
        "outputId": "53598015-3062-4cf3-b06d-d2598b326f5e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*What is a Ray Cluster?*\n",
        "In the simple example above, we run the code with Ray in just a single Ray instance / local service, without using a Ray Cluster. \n",
        "\n",
        "However, if we would like to scale the code to handle a larger workload, we can create a Ray Cluster. \n",
        "\n",
        "A Ray Cluster is a number of worker nodes that has a common head node. A Ray Cluster with multiple worker nodes enable a Python program to distribute its workload to the worker nodes, and each worker node will handle a different part of a computation asynchronously. \n",
        "\n",
        "After the worker nodes process different parts of a large workload, the output of the different parts will be coordinated and combined in a head node, allowing computations or workloads to be handled in a distributed manner. \n",
        "\n",
        "A Ray Cluster can be either fixed in size, or can be scaled up automatically, depending on its configuration. \n",
        "\n",
        "Usually, a Ray Cluster is deployed on a platform that supports it, like AWS, or Kubernetes.\n",
        "\n",
        "A Ray Cluster can be initialized by calling \n",
        "ray up cluster.yaml\n",
        "\n",
        "A cluster.yaml file can look like this:"
      ],
      "metadata": {
        "id": "Oi8sgOXVx5GR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cluster_name: str\n",
        "#max_workers: int\n",
        "#upscaling_speed: float\n",
        "#idle_timeout_minutes: int\n",
        "#docker:\n",
        "#    docker\n",
        "#provider:\n",
        "#    provider\n",
        "#auth:\n",
        "#    auth\n",
        "#available_node_types:\n",
        "#    node_types\n",
        "#head_node_type: str\n",
        "#file_mounts:\n",
        "#    file_mounts\n",
        "#cluster_synced_files:\n",
        "#    - str\n",
        "#rsync_exclude:\n",
        "#    - str\n",
        "#rsync_filter:\n",
        "#    - str\n",
        "#initialization_commands:\n",
        "#    - str\n",
        "#setup_commands:\n",
        "#    - str\n",
        "#head_setup_commands:\n",
        "#    - str\n",
        "#worker_setup_commands:\n",
        "#    - str\n",
        "#head_start_ray_commands:\n",
        "#    - str\n",
        "#worker_start_ray_commands:\n",
        "#    - str"
      ],
      "metadata": {
        "id": "OZcIpeC96_b2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*How to check Ray Cluster's resource(s)?*\n",
        "\n",
        "After initializing a Ray instance / service, we can check what type of resource(s) are available by calling .cluster_resources()"
      ],
      "metadata": {
        "id": "WmoxYsl802yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "import ray\n",
        "\n",
        "# Shut down any existing ray instance if there is one\n",
        "ray.shutdown()\n",
        "\n",
        "# Initialize Ray instance\n",
        "ray.init()\n",
        "\n",
        "# Check instance resource(s)\n",
        "pprint(ray.cluster_resources())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gpDzOci3khH",
        "outputId": "0ac2cb1d-69e6-4457-fcb7-d0e5093e8cfe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-16 09:36:25,872\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'CPU': 2.0,\n",
            " 'GPU': 1.0,\n",
            " 'accelerator_type:T4': 1.0,\n",
            " 'memory': 7936126158.0,\n",
            " 'node:172.28.0.12': 1.0,\n",
            " 'object_store_memory': 3968063078.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example output of a ray.cluster_resources() without GPU can look like this:\n",
        "\n",
        "{\n",
        " \n",
        " 'CPU': 2.0,\n",
        "\n",
        " 'memory': 7977271296.0,\n",
        "\n",
        " 'node:172.28.0.12': 1.0,\n",
        "\n",
        " 'object_store_memory': 3988635648.0\n",
        " \n",
        " }\n",
        "\n",
        "An example output of a ray.cluster_resources() with GPU can look like this:\n",
        "\n",
        " {\n",
        "   \n",
        "   'CPU': 2.0,\n",
        "\n",
        "   'GPU': 1.0,\n",
        "\n",
        "   'accelerator_type:T4': 1.0,\n",
        "\n",
        "   'memory': 7980692276.0,\n",
        "\n",
        "   'node:172.28.0.12': 1.0,\n",
        "\n",
        "   'object_store_memory': 3990346137.0\n",
        "   \n",
        "}\n",
        "\n",
        "An example output of a ray.cluster_resources() with GPU and multiple working nodes can look like this:\n",
        "\n",
        "{\n",
        " \n",
        " 'CPU': 208.0,\n",
        "\n",
        " 'GPU': 16.0,\n",
        "\n",
        " 'accelerator_type:T4': 4.0,\n",
        "\n",
        " 'memory': 616693614180.0,\n",
        "\n",
        " 'node:172.31.76.237': 1.0,\n",
        "\n",
        " 'node:172.31.80.117': 1.0,\n",
        "\n",
        " 'node:172.31.85.193': 1.0,\n",
        "\n",
        " 'node:172.31.85.32': 1.0,\n",
        "\n",
        " 'node:172.31.90.137': 1.0,\n",
        "\n",
        " 'object_store_memory': 259318055729.0\n",
        " \n",
        "}"
      ],
      "metadata": {
        "id": "_8hyFcNw4Rm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Using Ray AIR (AI Runtime) library to train an image classification ML model*\n",
        "\n",
        "In this tutorial we are going to look at how to scale the training of a Machine Learning Image Classification model using Ray AIR. \n",
        "\n",
        "The dataset used in training and testing the Image Classfication ML model is CIFAR10. \n",
        "\n",
        "CIFAR10 is a dataset containing 60,000 images, each with 32 x 32 image, in color-scale, with the images split into 50,000 as training images, and the rest 10,000 as test images. \n",
        "\n",
        "The CIFAR10 images can be classified into 10 categories. They are:\n",
        "\n",
        "Airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships and trucks. \n",
        "\n",
        "The compute resource required to train this image classifcation ML model is significant. \n",
        "\n",
        "According to this paper \"Automatically Designing CNN Architectures Using Genetic Algorithm for Image Classification\" (https://arxiv.org/pdf/1808.03818.pdf),\n",
        "\n",
        "With only a single machine, achieving a test accuracy above 90% requires 350 training epochs, and 32 GPU days in their method involving a genetic algorithm to find the most optimal Convolutional Neural Network structure. \n",
        "\n",
        "With Ray AIR, an example below (although not involving Genetic Algorithm), within just a few minutes, the number of epochs run can already be at 100 epochs. That means if it needs to run till 350 epochs, it only requires around or less than 30 minutes. \n",
        "\n",
        "In addition, with Ray Tune, we can tune the hyperparameters of the Convolutional Neural Network without using a Genetic Algorithm, which can again be achieved using multiple worker nodes, and train the image classification ML model in a distributed, asynchronous manner. "
      ],
      "metadata": {
        "id": "1c3JM-cT9GnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is taken from reviewing the image classification use case from the Ray AIR documentation\n",
        "# https://docs.ray.io/en/latest/ray-air/examples/torch_image_example.html\n",
        "# With my comments added for analysis purpose\n",
        "\n",
        "# Installing Ray AIR\n",
        "!pip install 'ray[air]'\n",
        "\n",
        "# Install requests, torch, and torchvision\n",
        "!pip install requests torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWi06ruZBSWt",
        "outputId": "2ad4aa55-339c-46f4-d6f0-cdaebb63c4e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray[air] in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (3.19.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (1.0.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray[air]) (4.3.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray[air]) (22.1.0)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (1.51.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (1.21.6)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray[air]) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray[air]) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray[air]) (2.23.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray[air]) (1.3.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray[air]) (1.3.1)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (20.17.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from ray[air]) (0.8.10)\n",
            "Requirement already satisfied: pyarrow<8.0.0,>=6.0.1 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (7.0.0)\n",
            "Requirement already satisfied: prometheus-client<0.14.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (0.13.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.8/dist-packages (from ray[air]) (0.20.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (2.5.1)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (3.8.3)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.8/dist-packages (from ray[air]) (0.11.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from ray[air]) (1.10.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.8/dist-packages (from ray[air]) (0.88.0)\n",
            "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (1.0.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.8/dist-packages (from ray[air]) (0.7.0)\n",
            "Requirement already satisfied: aiorwlock in /usr/local/lib/python3.8/dist-packages (from ray[air]) (1.3.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.8/dist-packages (from ray[air]) (5.2.1)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (1.3.5)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ray[air]) (0.3.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from ray[air]) (2022.11.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.8/dist-packages (from ray[air]) (0.5.5)\n",
            "Requirement already satisfied: starlette in /usr/local/lib/python3.8/dist-packages (from ray[air]) (0.22.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp>=3.7->ray[air]) (6.0.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp>=3.7->ray[air]) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp>=3.7->ray[air]) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp>=3.7->ray[air]) (1.8.2)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.8/dist-packages (from gpustat>=1.0.0->ray[air]) (1.15.0)\n",
            "Requirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /usr/local/lib/python3.8/dist-packages (from gpustat>=1.0.0->ray[air]) (11.495.46)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.8/dist-packages (from gpustat>=1.0.0->ray[air]) (5.9.4)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.8/dist-packages (from gpustat>=1.0.0->ray[air]) (1.19.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.8/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[air]) (0.2.5)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray[air]) (2.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray[air]) (0.3.6)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp>=3.7->ray[air]) (2.10)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from starlette->ray[air]) (3.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/dist-packages (from starlette->ray[air]) (4.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette->ray[air]) (1.3.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[air]) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray[air]) (0.19.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[air]) (3.11.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from opencensus->ray[air]) (2.8.2)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from opencensus->ray[air]) (0.1.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]) (2.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]) (1.57.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray[air]) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray[air]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->ray[air]) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3->ray[air]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3->ray[air]) (2022.6)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.8/dist-packages (from uvicorn->ray[air]) (0.14.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Transforming and Normalizing metrics\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "# Training set CIFAR10 downloaded from PyTorch\n",
        "train_dataset = torchvision.datasets.CIFAR10(\"data\", download=True, train=True, transform=transform)\n",
        "\n",
        "# Test set CIFAR10 downloaded from PyTorch\n",
        "test_dataset = torchvision.datasets.CIFAR10(\"data\", download=True, train=False, transform=transform)\n",
        "\n",
        "# Converting training set to Ray data\n",
        "train_dataset: ray.data.Dataset = ray.data.from_torch(train_dataset)\n",
        "\n",
        "# Converting test set to Ray data\n",
        "test_dataset: ray.data.Dataset = ray.data.from_torch(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYgM_UGhBuJv",
        "outputId": "0a09592c-69d1-46b4-c416-95c04189a024"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Tuple\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Defining method to convert Ray training / test dataset into numpy array\n",
        "def convert_batch_to_numpy(batch: Tuple[torch.Tensor, int]) -> Dict[str, np.ndarray]:\n",
        "    images = np.array([image.numpy() for image, _ in batch])\n",
        "    labels = np.array([label for _, label in batch])\n",
        "    return {\"image\": images, \"label\": labels}\n",
        "\n",
        "# Convert training and test sets to numpy arrays\n",
        "train_dataset = train_dataset.map_batches(convert_batch_to_numpy)\n",
        "test_dataset = test_dataset.map_batches(convert_batch_to_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq9QZlV8CfIS",
        "outputId": "4c26ef3c-babc-4d1b-890d-f01a940f1876"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map_Batches: 100%|██████████| 200/200 [00:21<00:00,  9.39it/s]\n",
            "Map_Batches: 100%|██████████| 200/200 [00:03<00:00, 55.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "\n",
        "# Import PyTorch Neural Network library that helps build neural networks\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Defining the Convolutional Neural Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Initialize the Convolutional Neural Network in the following structure\n",
        "        super().__init__()\n",
        "\n",
        "        # Add a convolutional layer\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "\n",
        "        # Add a max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Add a convolutional layer\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # Add Linear Layers with their respective inputs and outputs numbers\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "    # Define feed forward method\n",
        "    def forward(self, x):\n",
        "        # Use RELU (Rectified Linear Unit) in Convolutional Layer 1 and 2\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
        "\n",
        "        # Use RELU in Linear Layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "t8i4TUKTC2Rc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training is split into multiple smaller parts called \"Shards\" in a distributed manner by Ray Train and Ray AIR libraries. \n",
        "\n",
        "This speeds up training in a distributed manner by separately train the shards and combining the training outcome in the same session"
      ],
      "metadata": {
        "id": "W5qXg0ulF4Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import training library from Ray (Ray Train)\n",
        "from ray import train\n",
        "\n",
        "# Import session and checkpoint from Ray AIR\n",
        "from ray.air import session, Checkpoint\n",
        "\n",
        "# Import PyTorch checkpoint feature from Ray Train\n",
        "from ray.train.torch import TorchCheckpoint\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "# In each worker node, define method for training the Convolutional Neural Network\n",
        "# using Ray Train to scale training\n",
        "def train_loop_per_worker(config):\n",
        "\n",
        "    # Training the CNN model using Ray train and PyTorch\n",
        "    model = train.torch.prepare_model(Net())\n",
        "\n",
        "    # Using Cross Entropy Loss (A loss function metric used to measure how well the CNN classification model performs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Optimize the parameters of the Stochastic Gradient Descent learning rate and momentum\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    # Access training session's shards (The training is split into multiple smaller parts called Shards)\n",
        "    train_dataset_shard = session.get_dataset_shard(\"train\")\n",
        "\n",
        "    # Define how each epoch will enumerate\n",
        "    for epoch in range(2):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        # Split training dataset into subset of training data according to batch size\n",
        "        train_dataset_batches = train_dataset_shard.iter_torch_batches(\n",
        "            batch_size=config[\"batch_size\"],\n",
        "        )\n",
        "\n",
        "        # Iterate each batch in the already split training dataset batches \n",
        "        for i, batch in enumerate(train_dataset_batches):\n",
        "            # get the inputs and labels\n",
        "            inputs, labels = batch[\"image\"], batch[\"label\"]\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Get the loss metric and store into loss variable\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "                print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "        metrics = dict(running_loss=running_loss)\n",
        "        checkpoint = TorchCheckpoint.from_state_dict(model.module.state_dict())\n",
        "\n",
        "        # Save the model with checkpoint and metrics by using session.report \n",
        "        session.report(metrics, checkpoint=checkpoint)"
      ],
      "metadata": {
        "id": "fRIgNepQETua"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the training method for each worker node is defined above, call the training method. \n",
        "\n",
        "The number of worker nodes will be defined using ScalingConfig(num_workers = x)\n",
        "\n",
        "If we know that a GPU(s) is/are available, by calling ray.cluster_resouces(), we can then scale the training using a GPU by setting use_gpu=True in the ScalingConfig like so:\n",
        "\n",
        "scaling_config=ScalingConfig(num_workers=8, use_gpu=True)\n"
      ],
      "metadata": {
        "id": "Q6hyFasRH1ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Convolutional Neural Network by calling the train_loop_per_worker method defined above\n",
        "\n",
        "from ray.train.torch import TorchTrainer\n",
        "from ray.air.config import ScalingConfig\n",
        "\n",
        "trainer = TorchTrainer(\n",
        "    train_loop_per_worker=train_loop_per_worker,\n",
        "    train_loop_config={\"batch_size\": 2},\n",
        "    datasets={\"train\": train_dataset},\n",
        "    scaling_config=ScalingConfig(num_workers=2),\n",
        "    # If GPU is available, and wish to use it, we can set use_gpu = True\n",
        "    #scaling_config=ScalingConfig(num_workers=2, use_gpu=True)\n",
        ")\n",
        "# Recording the starting time\n",
        "training_start_time = time.time()\n",
        "\n",
        "result = trainer.fit()\n",
        "\n",
        "# Print the time it takes for the Ray remote function to execute\n",
        "training_execution_time1 = time.time() - start_time\n",
        "print(training_execution_time1)\n",
        "\n",
        "latest_checkpoint = result.checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "i845sWDHHh3t",
        "outputId": "f3d582c8-01a7-43d1-92b3-9002c8c65765"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-16 09:37:37,180\tINFO data_parallel_trainer.py:286 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
            "/usr/local/lib/python3.8/dist-packages/ray/train/base_trainer.py:354: UserWarning: Executing `.fit()` may leave less than 20% of CPUs in this cluster for Dataset execution, which can lead to resource contention or hangs. To avoid this, reserve at least 20% of node CPUs for Dataset execution by setting `_max_cpu_fraction_per_node = 0.8` in the Trainer scaling_config. See https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune for more info.\n",
            "  tuner = Tuner(trainable=trainable, run_config=self.run_config)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2022-12-16 09:40:08</td></tr>\n",
              "<tr><td>Running for: </td><td>00:02:30.99        </td></tr>\n",
              "<tr><td>Memory:      </td><td>3.2/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.39 GiB heap, 0.0/3.7 GiB objects (0.0/1.0 accelerator_type:T4)\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name              </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  running_loss</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _time_this_iter_s</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>TorchTrainer_46be6_00000</td><td>TERMINATED</td><td>172.28.0.12:11735</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         144.477</td><td style=\"text-align: right;\">       647.838</td><td style=\"text-align: right;\">  1671183605</td><td style=\"text-align: right;\">            68.3733</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(TorchTrainer pid=11735)\u001b[0m 2022-12-16 09:37:41,418\tINFO data_parallel_trainer.py:286 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m 2022-12-16 09:37:46,324\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m 2022-12-16 09:37:47,863\tINFO train_loop_utils.py:270 -- Moving model to device: cpu\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m 2022-12-16 09:37:47,865\tINFO train_loop_utils.py:330 -- Wrapping provided model in DistributedDataParallel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [1,  2000] loss: 2.227\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [1,  2000] loss: 2.227\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [1,  4000] loss: 1.856\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [1,  4000] loss: 1.858\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [1,  6000] loss: 1.634\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [1,  6000] loss: 1.681\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [1,  8000] loss: 1.594\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [1,  8000] loss: 1.549\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [1, 10000] loss: 1.516\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [1, 10000] loss: 1.528\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [1, 12000] loss: 1.473\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [1, 12000] loss: 1.477\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name              </th><th style=\"text-align: right;\">  _time_this_iter_s</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  running_loss</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>TorchTrainer_46be6_00000</td><td style=\"text-align: right;\">            68.3733</td><td style=\"text-align: right;\">  1671183605</td><td style=\"text-align: right;\">                    2</td><td>2022-12-16_09-40-05</td><td>True  </td><td>                </td><td>dcc6413f4f6d4281afbcb58a3f5155a1</td><td style=\"text-align: right;\">               0</td><td>1ca39f28017b</td><td style=\"text-align: right;\">                         2</td><td>172.28.0.12</td><td style=\"text-align: right;\">11735</td><td style=\"text-align: right;\">       647.838</td><td>True               </td><td style=\"text-align: right;\">             144.477</td><td style=\"text-align: right;\">           68.3411</td><td style=\"text-align: right;\">       144.477</td><td style=\"text-align: right;\"> 1671183605</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   2</td><td>46be6_00000</td><td style=\"text-align: right;\">    0.0917635</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [2,  2000] loss: 1.451\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [2,  2000] loss: 1.443\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [2,  4000] loss: 1.413\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [2,  4000] loss: 1.429\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [2,  6000] loss: 1.355\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [2,  6000] loss: 1.386\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [2,  8000] loss: 1.358\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [2,  8000] loss: 1.332\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [2, 10000] loss: 1.315\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [2, 10000] loss: 1.331\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11774)\u001b[0m [2, 12000] loss: 1.291\n",
            "\u001b[2m\u001b[36m(RayTrainWorker pid=11775)\u001b[0m [2, 12000] loss: 1.314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-16 09:40:08,619\tINFO tune.py:762 -- Total run time: 151.40 seconds (150.97 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "231.77885127067566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For comparison purpose, we can change the number of worker nodes in ScalingConfig to see the difference in training time."
      ],
      "metadata": {
        "id": "i7fcs3xFO50F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the CNN Image Classification model is trained in a distributed way using Ray, we can test the model's accuracy on the test data by creating a Predictor:"
      ],
      "metadata": {
        "id": "dXQ_ZvhXJMXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.train.torch import TorchPredictor\n",
        "from ray.train.batch_predictor import BatchPredictor\n",
        "\n",
        "batch_predictor = BatchPredictor.from_checkpoint(\n",
        "    checkpoint=latest_checkpoint,\n",
        "    predictor_cls=TorchPredictor,\n",
        "    model=Net(),\n",
        ")\n",
        "\n",
        "outputs: ray.data.Dataset = batch_predictor.predict(\n",
        "    data=test_dataset,\n",
        "    dtype=torch.float,\n",
        "    feature_columns=[\"image\"],\n",
        "    keep_columns=[\"label\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-qePDFeJLNC",
        "outputId": "f92ab487-41de-4996-9dec-9203f7d45f3b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-12-16 09:40:08,689\tWARNING compute.py:520 -- `batch_size` is set to 4096, which reduces parallelism from 200 to 3. If the performance is worse than expected, this may indicate that the batch size is too large or the input block size is too small. To reduce batch size, consider decreasing `batch_size` or use the default in `map_batches`. To increase input block size, consider decreasing `parallelism` in read.\n",
            "Map Progress (1 actors 1 pending): 100%|██████████| 3/3 [00:05<00:00,  1.72s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Predictor calculates a score representing each class of an image. Among the 10 classes, the class that has the highest score is the most likely class that the image is classified into. "
      ],
      "metadata": {
        "id": "vkouzWUuJmTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Getting the highest score (most likely class of an image, and return the class label number)\n",
        "def convert_logits_to_classes(df):\n",
        "    best_class = df[\"predictions\"].map(lambda x: x.argmax())\n",
        "    df[\"prediction\"] = best_class\n",
        "    return df[[\"prediction\", \"label\"]]\n",
        "\n",
        "\n",
        "predictions = outputs.map_batches(convert_logits_to_classes)\n",
        "\n",
        "predictions.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh2ybLxhJ8nr",
        "outputId": "59aae777-0a62-477e-ea9f-59da1d91ad66"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map_Batches: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prediction': 3, 'label': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the predictor result with actual result and store the scores "
      ],
      "metadata": {
        "id": "Df05y1X7Kftz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prediction_scores(df):\n",
        "    df[\"correct\"] = df[\"prediction\"] == df[\"label\"]\n",
        "    return df\n",
        "\n",
        "\n",
        "scores = predictions.map_batches(calculate_prediction_scores)\n",
        "\n",
        "scores.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-8ydfj1KbY6",
        "outputId": "0a3aab21-2d6c-487b-db0a-162d4a6ec12c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Map_Batches: 100%|██████████| 3/3 [00:00<00:00, 22.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prediction': 3, 'label': 3, 'correct': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we want to know how well the CNN model is performing, by calculating how many test images the model has classified correctly, divided by the total number of test images"
      ],
      "metadata": {
        "id": "j0kkX500Ke5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores.sum(on=\"correct\") / scores.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0iPWk_4K_9Z",
        "outputId": "a07bb26e-86bb-400f-847c-f7801e9298f6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Shuffle Map: 100%|██████████| 3/3 [00:00<00:00, 72.43it/s]\n",
            "Shuffle Reduce: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5343"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The example above shows how we can use Ray, Ray Train, and Ray AIR to train a Convolutional Neural Network for Image Classification purpose. \n",
        "\n",
        "By using Ray Train and Ray AIR, the training of the model can be split into shards (smaller pieces) and trained asynchronously. \n",
        "\n",
        "The shards can be handled by the number of worker nodes specified in ScalingConfig. \n",
        "\n",
        "scaling_config=ScalingConfig(num_workers=8, use_gpu=True)\n",
        "\n",
        "The more number of workers, with all else equal (same number in training and testing images, etc.), the faster the training can be done. \n",
        "\n",
        "In the example above, the CIFAR10 dataset is used, which contains 60,000 images, with 50,000 training images, and 10,000 test images. If the number of images increases to a very large number, these images can be split into batches and separately handled by multiple worker nodes, and the result of the training (the weights of the Convolutional Neural Network) can be combined and used to predict and classify a test image. \n",
        "\n",
        "With distributed worker nodes sharing the workload of both the dataset and training the model asynchronously, the training time can be greatly reduced, in comparison with using only a single machine to train the model. \n",
        "\n",
        "This example and tutorial concludes that Ray is a powerful tool to handle big data, and be able to divide and conquer a long, large training job of training a Convolutional Neural Network for image classification purpose. "
      ],
      "metadata": {
        "id": "W8pY3e3XLBoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References: \n",
        "\n",
        "https://www.ray.io\n",
        "\n",
        "https://docs.ray.io/en/latest/ray-air/examples/torch_image_example.html"
      ],
      "metadata": {
        "id": "ElBBXApG0yLm"
      }
    }
  ]
}